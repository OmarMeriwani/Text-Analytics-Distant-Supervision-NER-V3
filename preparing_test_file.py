# -*- coding: utf-8 -*-
"""preparing test file.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zxTYavHtoj8NwdzO8r7qryVOvI3B0QNC
"""

import pandas as pd
import numpy as np
import csv
import nltk
from google.colab import files
from google.colab import drive
import nltk
nltk.download('averaged_perceptron_tagger')

drive.mount('/content/drive/')

engine='python'
!ls "/content/drive/My Drive/Essex/textanalytics/"
file = open('/content/drive/My Drive/Essex/textanalytics/wikigold.conll.txt','r')
tokens = file.read().split('\n')
postaglist = []
print(tokens)
for i in tokens:
  i = i.rstrip('\r\n')
  splittedword = i.split(' ')
  if (len(splittedword) < 2):
    splittedword = [' ','O']
  word = splittedword[0]
  iob = splittedword[1]
  postaglist.append(word)
tagged_tokens = nltk.pos_tag(postaglist)
df = pd.DataFrame(columns=['word','pos','iob'])
print(len(tagged_tokens))
print(len(tokens))
for i in range(0,len(tokens)):
  splittedword = tokens[i].split(' ')
  if (len(splittedword) < 2):
    splittedword = [' ','O']
  word = splittedword[0]
  iob = splittedword[1]
  pos = tagged_tokens[i][1]
  df.loc[i]=[word,pos,iob]
df.to_csv('/content/drive/My Drive/Essex/textanalytics/wikigoldPOS.csv')
#textdata = pd.read_csv('https://github.com/OmarMeriwani/Text-Analytics-Distant-Supervision-NER-V3/blob/master/wikigold.conll.txt',sep=',')
#tokens = textdata.read().split(' ')
'''
df = pd.DataFrame(columns=['word','iob'])
seq = 1
for i in textdata:
  print(seq)
  word = i[0]
  iob = i[1]
  df.loc[seq]=[word,iob]
  previousWord = word
  seq += 1
#tagged_tokens = nltk.pos_tag(word_list)
with open('TestDS.csv', mode='w') as csvfile:
    if seq % 10000 == 0:
        print(seq)
        df.to_csv(csvfile, header=False)
        df = pd.DataFrame(columns=['word', 'pos', 'uppercase', 'prevPOS', 'PrevWord', 'iob', 'VectorCount'])
        # break
        seq = seq + 1
print(len(df))
'''